---
layout: post
title: "AI现状：基于100万亿Token的实证研究"
date: 2025-12-11
categories:
    - AI
tags:
    - llm
---
**说明**：这是一份完全让由AI（豆包、Gemini、千问）生成的总结，我只做了内容提取和对比整合工作。学习报告内容的同时也对比下主流模型和APP的能力，原始报告来自[OpenRouter平台](https://openrouter.ai/state-of-ai){:target="_blank"}，需完整内容可以看原文[^1]。

研究基于对OpenRouter平台上超过100万亿token的真实LLM交互数据分析，提供了一个关于大型语言模型（LLMs）实际使用情况的经验性视角。

报告分析了2024年底至2025年间大型语言模型（LLMs）的真实世界使用模式。研究发现，随着OpenAI的o1等推理模型的推出，市场从单次文本生成转向了多步骤、工具调用和推理密集型的工作流程，即“代理式推理”正在崛起。数据揭示，尽管编程任务在所有LLM使用中占据主导且增长最快，但创意角色扮演却在开源模型（OSS）的使用中占据超过一半的份额，表明用户需求具有复杂的多样性。此外，报告还提出了“灰姑娘玻璃鞋效应”，即最早找到模型-工作负载完美契合的早期用户群体（Foundational Cohorts）会表现出显著且持久的留存率，这成为衡量模型价值的关键指标。整体而言，LLM生态系统是多元化且竞争激烈的，闭源模型和开源模型分别在高价值和高容量任务中发挥作用，并且亚洲市场的份额正在迅速扩大。 -- from Gemini

<!--more-->

### 一、研究基础

* 研究背景：2024年12月OpenAI o1模型发布后，LLM领域从单轮模式生成转向多步审慎推理，本研究基于OpenRouter平台超100万亿token的真实交互数据，填补了LLM实际使用场景的实证认知空白。
* 数据范围：覆盖2024年11月-2025年11月（部分分类数据始于2025年5月），包含全球数百万开发者/用户、300+活跃模型、60+提供商，50%以上使用量来自美国以外地区。
* 研究维度：开源vs闭源模型、智能体推理、任务分类、地理分布、成本-使用动态、用户留存六大核心方向。


### 二、核心发现

**1. 模型生态：开源与闭源双轨并行**
* 闭源模型仍占主导（约70%token份额），但开源模型稳步增长至2025年末的30%，其中中国开源模型（如Qwen、DeepSeek）从1.2%增至近30%（部分周），平均占比13%。
* 开源模型市场从DeepSeek垄断转向多元化，Qwen、Meta LLaMA、Mistral AI等跻身前列，中等规模模型（150-700亿参数）成为新热点，小型模型（<150亿参数）使用率下降。
* 开源模型擅长创意角色扮演（占比52%）和编程辅助（15-20%），闭源模型主导结构化商业任务。

**2. 用法变迁：智能体推理崛起**
* 推理型模型使用率从2025年初近乎为零增至超50%，xAI的Grok Code Fast 1、Google Gemini 2.5系列成为核心驱动。
* 工具调用呈持续上升趋势，Anthropic Claude、Google Gemini等模型主导该场景，2025年中后开源模型逐步入局。
* 交互复杂度提升：平均提示词 tokens 增长4倍（1.5K→6K），输出 tokens 增长3倍（150→400），编程任务是长序列交互（超20K tokens）的主要驱动。

**3. 任务分类：编程与角色扮演主导**
* 编程成为第一大任务类别，从2025年初11%增至近50%，Anthropic Claude系列占该领域60%以上使用量，OpenAI、Google及开源模型逐步分流份额。
* 角色扮演是开源模型第一大用途（52%），闭源与开源模型在该场景占比接近（42% vs 43%），远超预期。
* 其他任务中，翻译、知识问答、教育占比有限，科学类查询多集中于机器学习/AI主题（80.4%），健康、金融类任务呈碎片化分布。

**4. 地理与语言：全球分布多元化**
* 北美仍为最大市场（占比<50%），欧洲份额稳定（15-20%），亚洲占比从13%翻倍至31%。
* 语言方面，英语占82.87%，简体中文占4.95%，俄语（2.47%）、西班牙语（1.43%）等构成次要语言。

**5. 用户留存：灰姑娘“水晶鞋”效应**
* 早期用户群体留存率显著高于后期用户，如2025年5-6月的Claude 4 Sonnet、Gemini 2.5 Pro用户，5个月后留存率约40%。
* 核心逻辑：模型与用户高价值需求实现精准匹配（“水晶鞋契合”），用户因技术适配、成本惯性形成强锁定，DeepSeek模型出现“回流效应”（流失用户回归）。

**6. 成本-使用：非完全价格敏感**
* 市场分为四大象限：编程/角色扮演（高用量低 cost）、技术/科学（高用量高 cost）、金融/健康（低用量高 cost）、翻译/ trivia（低用量低 cost）。
* 需求价格弹性弱：10%降价仅带来0.5-0.7%用量增长，闭源模型占据高价值高 cost 领域，开源模型主导高用量低 cost 场景。
* 质量与可靠性优先于价格，Anthropic Claude、OpenAI GPT-4等高价模型因性能优势保持高使用率。

-- from 豆包

### 三、观点提炼

**关键范式转变：**
LLM领域经历了重大转折，正在从单次文本生成转向多步骤的**智能体推理**（Agentic Inference），涉及内部审议、潜在规划和迭代细化。推理优化模型的token使用份额在2025年迅速上升，现已超过总使用量的一半 。这一转变也体现在工作负载的复杂性增加上，平均提示token长度增长了近四倍，主要驱动因素是编程工作负载需要处理大量的上下文信息。

**生态系统结构与竞争：**
LLM生态系统是**结构性多元化**的，闭源和开源模型都占据了重要份额。虽然专有模型仍占多数token使用量，但开源模型已稳步增长，到2025年末达到总使用量的约三分之一。尤其值得注意的是，中国开源模型（Chinese OSS）迅速崛起，其增长态势和迭代速度重塑了开源领域，并在某些周内达到了所有模型总使用量的近30%。开源模型的市场格局正走向**碎片化**，多个模型家族共同维持可观的使用份额，而不再由单一模型主导。

**主要应用领域：**
实际使用情况复杂且多面，最主要的活动集中在**编程辅助**和**创意角色扮演**两大类别。在所有LLM查询中，**编程**是增长最快且占主导地位的类别，在最近几周内占总token量的比例已超过50%。对于开源模型而言，**角色扮演**占据了超过一半的使用量，这表明用户利用开源模型的定制化和内容限制较少的特点，主要用于互动对话和创意场景。

**经济与留存模式：**
LLM市场的需求对价格相对缺乏弹性，但模型的使用情况存在显著的**市场细分** 。闭源模型通常占据高成本、高使用量的“卓越领导者”象限，用于高价值或任务关键型工作负载，而开源模型则倾向于低成本、高使用量的“高效巨头”领域，满足成本敏感型需求。模型的长期留存由**“灰姑娘的水晶鞋”效应**决定，即早期用户队列一旦发现模型与特定工作负载完美匹配，就会形成持久的参与度，抵抗后续模型更迭带来的替代效应。

**地域分布：**
LLM使用量正变得越来越全球化和去中心化。北美仍然是最大的单一地区，但在大部分观察期内占总支出的比例不到一半。亚洲地区的份额显著增长，目前已达到约31%。全球竞争的下一阶段将取决于模型的文化适应性和多语言能力。

### 四、关键启示

**豆包模型辅助总结**
* 模型生态趋向多元化，多模型集成成为开发者首选，而非单一依赖。
* 消费级娱乐（角色扮演）与专业生产力（编程）同为LLM核心需求，模型评估需兼顾创意性与实用性。
* 智能体推理成为竞争核心，工具调用、长上下文处理、多步推理能力决定模型上限。
* 全球市场与多语言支持成为必备能力，中国开源模型在全球竞争中占据重要地位。
* 留存率比短期增长更关键，“首次精准匹配”是模型长期占据市场的核心优势。

**千问模型辅助总结[^2]**
* 开源生态重构：中国开源模型通过快速迭代和本地化优势，与西方模型形成双寡头竞争格局，DeepSeek、Qwen等模型在代码生成领域表现突出。
* 代理式推理革命：推理模型使用量突破50%大关，工具调用频率年增300%，标志着LLM从文本生成向任务执行范式转变。
* 应用场景颠覆认知：角色扮演类应用占据开源模型52%token份额，编程类应用呈现"长上下文+短输出"特征，平均输入token达6K。
* 市场突破密码：灰姑娘玻璃鞋效应揭示，模型市场突破的关键在于解决特定工作负载的"技术-经济约束"，而非单纯性能领先。


总而言之，该研究通过大规模数据揭示了LLM正在成为跨域（从编程到创意写作）的**基本计算基质**。未来的竞争将取决于运营卓越性、对真实任务完成度的衡量，以及对多模型、多语言生态的适应能力。

### 参考资料

[^1]: *[An Empirical 100 Trillion Token Study with OpenRouter](https://openrouter.ai/state-of-ai){:target="_blank"}*
[^2]: *[千问阅读助手](https://www.qianwen.com/efficiency/doc/read?taskId=bBVThTWD5uNP1sc9yWD8iWT0FXMGwgzh&isShare=true){:target="_blank"}*
